16장 강화학습
============

#### 행동심리학과 강화학습
강화(Reinforcement)는 동물이 시행착오(Trial and Error)을 통해 학습하는 방법 중 하나로 강화의 핵심은 바로 **보상을 얻게 해주는 행동**의 빈도 증가
#### 기계학습과 강화학습
기계학습은 인공지능의 한 범주로 서 컴퓨터가 스스로 학습하게 하는 알고리즘을 개발하는 연구분야
종류 : 지도학습, 비지도 학습, **강화학습**

### 강화학습(Reinforcement learning)

어떤 환경을 탐색하는 에이전트(Agent)가 현재의 상태(State)를 인식하여 어떤 행동(Action)을 취한다. 그러면 그 에이전트는 환경(Envirionment)으로부터 포상(Reward)을 얻게 된다. 포상은 양수와 음수 둘 다 가능하다. 강화 학습의 알고리즘은 그 에이전트가 앞으로 누적될 포상을 최대화하는 일련의 행동으로 정의되는 정책을 찾는 방법이다.

1. 보상(Reward)을 통해 학습
2. 보상은 컴퓨터가 선택한 행동(Action)에 대한 환경의 반응
3. 따라서 **행동이 결과로 나타나는 보상을 통해 학습**
4. 보상을 얻게하는 행동을 점점 많이 하도록 학습

### 배경

* 1950년대 부터 시작해 주로 게임과 제어분야에 응용
* 2013년 영국 스타트업 딥마인드 팀이 아타리 게임에 적용한것을 시연하면서 혁명이 일어남
* 2014년 구글이 딥마인드를 5억달러에 인수
* 2017년 알파고가 커제를 이기면서 절정
* 강화학습에 딥러닝을 적용했더니 상상 이상의 성능 발휘함

### 주요개념

* 정책 그레디언트(Policy gradient)
* 심층 Q-네트워크(DQN)
* 마르코프 결정과정(MDP)

## 16.1 보상을 최적화하기 위한 학습

* 소프트웨어 에이전트(Agent)는 주어진 환경(Environment)에서 행동(Action)을 하고 그 결과로 보상(Reward)을 받음
* 에이전트의 목적은 보상의 장기간 **기대치를 최대**로 만드는 행동을 학습하는것
* 양(positive)보상, 음(negative)보상이 있고 시행착오 끝에 합한 보상이 최대가 되게 하는것
   
ex) 보행로봇 제어 프로그램의 경우 환경은 실제세상, 에이전트는 센서를 통해 세상 관찰   
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;에이전트가 아타리 제어 프로그램인 경우 환경은 아타리 게임 시뮬레이션이고 액션은 조이스틱 위치
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;


## 16.2 정책 탐색

<img width="435" src="https://user-images.githubusercontent.com/4945207/74102427-c3bf0c80-4b86-11ea-8a22-8663ea41e7f6.png"></img>

* 정책(policy) : 에이전트가 행동을 결정하기 위해 사용하는 알고리즘 ex)신경망 정책
* 정책 파라미터 : 정책을 결정하는 변경 가능한 파라미터
* 정책 탐색 : 에이전트가 가장 성능좋은 조합을 고르기 위한 과정   
> 무작위 탐색
> 유전 알고리즘
* 정책 공간 : 정책탐색을 위한 공간
* 관측(obeervation) : 
* 보상(reward) : 

## 16.3 OpenAI 짐

* 에이전트를 훈련시키기 위한 시뮬레이션 환경
* https://gym.openai.com

### CartPole 환경 시물레이션

카트위에 놓인 막대가 넘어지지 않도록 카트를 왼쪽 또는 오른쪽으로 가속시키는 2D 시뮬레이션


