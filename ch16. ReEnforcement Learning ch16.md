16장 강화학습
===========================

### 배경

* 1950년대 부터 시작해 주로 게임과 제어분야에 응용
* 2013년 영국 스타트업 딥마인드 팀이 아타리 게임에 적용한것을 시연하면서 혁명이 일어남
* 2014년 구글이 딥마인드를 5억달러에 인수
* 2017년 알파고가 커제를 이기면서 절정
* 강화학습에 딥러닝을 적용했더니 상상 이상의 성능 발휘함

### 주요개념

* 정책 그레디언트(Policy gradient)
* 심층 Q-네트워크(DQN)
* 마르코프 결정과정(MDP)

## 16.1 보상을 최적화하기 위한 학습

* 소프트웨어 에이전트(Agent)는 주어진 환경(Environment)에서 행동(Action)을 하고 그 결과로 보상(Reward)을 받음
* 에이전트의 목적은 보상의 장기간 **기대치를 최대**로 만드는 행동을 학습하는것
* 양(positive)보상, 음(negative)보상이 있고 시행착오 끝에 합한 보상이 최대가 되게 하는것
   
ex) 보행로봇 제어 프로그램의 경우 환경은 실제세상, 에이전트는 센서를 통해 세상 관찰   
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;에이전트가 아타리 제어 프로그램인 경우 환경은 아타리 게임 시뮬레이션이고 액션은 조이스틱 위치
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;


## 16.2 정책 탐색

<img width="435" src="https://user-images.githubusercontent.com/4945207/74102427-c3bf0c80-4b86-11ea-8a22-8663ea41e7f6.png"></img>

* 정책(policy) : 에이전트가 행동을 결정하기 위해 사용하는 알고리즘 ex)신경망 정책
* 정책 파라미터 : 정책을 결정하는 변경 가능한 파라미터
* 정책 탐색 : 에이전트가 가장 성능좋은 조합을 고르기 위한 과정   
> 무작위 탐색
> 유전 알고리즘
* 정책 공간 : 정책탐색을 위한 공간
* 관측(obeervation) : 
* 보상(reward) : 

## 16.3 OpenAI 짐

* 에이전트를 훈련시키기 위한 시뮬레이션 환경
* https://gym.openai.com

### CartPole 환경 시물레이션

카트위에 놓인 막대가 넘어지지 않도록 카트를 왼쪽 또는 오른쪽으로 가속시키는 2D 시뮬레이션


